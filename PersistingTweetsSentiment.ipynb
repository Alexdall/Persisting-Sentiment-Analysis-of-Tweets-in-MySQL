{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi everybody , this little snippet will show you how to use the Twitter API and do the sentiment analysis for the each tweet found. We'll use different Python libs to make this exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you need to do is import the necessary libraries to use. In this case we'll need the TWEEPY in order to make a twitter connection, TEXTBLOB to run a sentiment analysis, TIME and DATETIME to control a pause (I explain this point better bellow) and record the time that the register was inserted in a database and MYSQL.CONNECTOR in order to connect and use the MySQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "import datetime\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After import the libs, we'll develop a function that makes a connection, passing the parameters to mysql connect method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = mysql.connector.connect(host='localhost',\n",
    "                             database='database_name',\n",
    "                             user='user',\n",
    "                             password='password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we need to create a cursor passing the necessary insert statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor(prepared=True)\n",
    "        sql_insert_query = '''INSERT INTO `tweets`.`tweets_table`(`Date`,`Author`, `Text`, `Translate`, `Sentiment`, `Sensation`)VALUES(%s,%s,%s,%s,%s,%s)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the cursor is instantiated and the record found is commited in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_tuple = (p_date,p_author, p_text, p_translate, p_sentiment,p_sensation)\n",
    "        result = cursor.execute(sql_insert_query, insert_tuple)\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To each entry commited, a message is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Record inserted successfully into tweets_table table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I case of an error, a try.. except handles, makes a rollback and shows the error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "except mysql.connector.Error as error :\n",
    "        connection.rollback()\n",
    "        print(\"Failed to insert into MySQL table {}\".format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "At the end, a finally block close the cursor and database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finally:\n",
    "        #closing database connection.\n",
    "        if(connection.is_connected()):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the first part of the code completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import timeimport pandas as pd\n",
    "from textblob import TextBlob\n",
    "import datetime\n",
    "import mysql.connector\n",
    "\n",
    "def insertInTable(p_date,p_author, p_text, p_translate, p_sentiment,p_sensation):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost',\n",
    "                             database='databaase_name',\n",
    "                             user='user',\n",
    "                             password='password')\n",
    "        cursor = connection.cursor(prepared=True)\n",
    "        sql_insert_query = '''INSERT INTO `tweets`.`tweets_table`(`Date`,`Author`, `Text`, `Translate`, `Sentiment`, `Sensation`)VALUES(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "        insert_tuple = (p_data,p_autor, p_texto, p_traducao, p_sentimento,p_sensacao)\n",
    "        result = cursor.execute(sql_insert_query, insert_tuple)\n",
    "        connection.commit()\n",
    "        print (\"Record inserted successfully into tweets_table table\")\n",
    "    except mysql.connector.Error as error :\n",
    "        connection.rollback()\n",
    "        print(\"Failed to insert into MySQL table {}\".format(error))\n",
    "    finally:\n",
    "        #closing database connection.\n",
    "        if(connection.is_connected()):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"MySQL connection is closed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the function is finished it is time to start the connections with Twitter. \n",
    "\n",
    "I will not explain in this topic how to get the required key and token. This information can be obtained from the address below:\n",
    "\n",
    "https://developer.twitter.com/\n",
    "\n",
    "Here you will find all the information to create an account and get the key and token, as well as find all the API documentation for several languages like Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to pass the necessary connection information, all obtained from the site mentioned above. The information below is fake, it's only being used as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'Baks8re9889rwe8r9we80r9we809r8q'\n",
    "consumer_secret = '219uewqiueqwiur09wq898092hewqkj'\n",
    "access_token = 'ifudsaoifsdafpsdaipofisdapipc098098q423'\n",
    "access_secret = 'rwe87r0we88re09tre9twe9rd8937423ji'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to pass the information and make a connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Downloading and Persisting tweets...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cursor we will pass the necessary parameters to the search API, such as the word to be searched, number of records per\n",
    "page, whether to bring retweets or not and other fields that will be stored in the table as date, author, tweeted text and \n",
    "so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q=\"word\",\n",
    "                           rpp=100,\n",
    "                           tweet_mode='extended',\n",
    "                           result_type=\"recent\",\n",
    "                           include_entities=True,\n",
    "                           lang=\"pt-br\").items(1000):\n",
    "    if not tweet.retweeted and ('RT @' not in tweet.full_text):\n",
    "        data = tweet.created_at\n",
    "        autor = tweet.author.screen_name\n",
    "        texto = tweet.full_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each processed tweet we will use the textblob to return the sentiment analysis. \n",
    "\n",
    "If we are working with other languages (in my case I was finding brasilian portuguese tweets), we can choose to translate the tweet into English and perform the feeling analysis considering that the English language is simpler and the algorithms more mature. Obviously, for very regional expressions we cannot get the correct analysis, but like the whole statistical algorithm, we will not hit 100% of the cases, but for most of the common expressions it works very well.\n",
    "\n",
    "You can use textblob in order to make classifications (Naive Bayes and decision trees), tokenization, n-grams, word inflection, etc.\n",
    "\n",
    "As the website itself says: TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "\n",
    "More information of TextBlob can be found here: https://textblob.readthedocs.io/en/dev/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each tweet is passed to the textblob that does the translation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = TextBlob(texto)\n",
    "        translate = TextBlob(str(frase.translate(to='en')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we'll analyse the polarity and return the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = translate.sentiment\n",
    "        if sentiment.polarity < 0.0:\n",
    "            sentiment2 = 'Negative'\n",
    "        elif sentiment.polarity == 0.0:\n",
    "            sentiment2 = 'Neutral'\n",
    "        else:\n",
    "            sentiment2 = 'Positive'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time sleep is needed to prevent twitter from rating the program as a robot and blocking access to the API. \n",
    "this procedure is highly recommended. I learned after being blocked several times kkkkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally you just get the time of the registry entry and write everything into the MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        insertInTable(now, author, text, str(translate), str(sentiment), sentiment2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the completed code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import timeimport pandas as pd\n",
    "from textblob import TextBlob\n",
    "import datetime\n",
    "import mysql.connector\n",
    "def insertInTable(p_date,p_author, p_text, p_translate, p_sentiment,p_sensation):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost',\n",
    "                             database='database_name',\n",
    "                             user='user',\n",
    "                             password='password')\n",
    "        cursor = connection.cursor(prepared=True)\n",
    "        sql_insert_query = '''INSERT INTO `tweets`.`tweets_table`(`Date`,`Author`, `Text`, `Translate`, `Sentiment`, `Sensation`)VALUES(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "        insert_tuple = (p_date,p_author, p_text, p_translate, p_sentiment,p_sensation)\n",
    "        result = cursor.execute(sql_insert_query, insert_tuple)\n",
    "        connection.commit()\n",
    "        print (\"Record inserted successfully into tweets_table table\")\n",
    "    except mysql.connector.Error as error :\n",
    "        connection.rollback()\n",
    "        print(\"Failed to insert into MySQL table {}\".format(error))\n",
    "    finally:\n",
    "        #closing database connection.\n",
    "        if(connection.is_connected()):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"MySQL connection is closed\")\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q=\"word\",\n",
    "                           rpp=100,\n",
    "                           tweet_mode='extended',\n",
    "                           result_type=\"recent\",\n",
    "                           include_entities=True,\n",
    "                           lang=\"pt-br\").items(1000):\n",
    "    if not tweet.retweeted and ('RT @' not in tweet.full_text):\n",
    "        data = tweet.created_at\n",
    "        autor = tweet.author.screen_name\n",
    "        text = tweet.full_text\n",
    "        phrase = TextBlob(texto)\n",
    "        translate = TextBlob(str(phrase.translate(to='en')))\n",
    "        sentiment = traducao.sentiment\n",
    "        if sentiment.polarity < 0.0:\n",
    "            sentiment2 = 'Negative'\n",
    "        elif sentiment.polarity == 0.0:\n",
    "            sentiment2 = 'Neutral'\n",
    "        else:\n",
    "            sentiment2 = 'Positive'\n",
    "        time.sleep(10)\n",
    "        print(author + \"-\" + text + \"-\" + str(sentiment) + \"-\" + str(sentiment2))\n",
    "        now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        insertInTable(now, author, text, str(translate), str(sentiment), sentiment2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this few lines of code we can start storing a large amount of text for later use in other machine learning analysis.\n",
    "\n",
    "You can use this code to make a spider and store web page content as well. You can find more information in this topic: A Little Snippet to Automate Web Scraping using Python and Selenium \n",
    "\n",
    "I hope you enjoyed the topic and see you next time!\n",
    "\n",
    "Enjoy the code, improve it if you want to!\n",
    "\n",
    "See you!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
